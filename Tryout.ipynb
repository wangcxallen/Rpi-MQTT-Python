{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = np.array([[1, 2, -3, 0, 1, -3], \n",
    "                  [3, 1, 2, 1, 0, 2], \n",
    "                  [2, 2, 2, 2, 2, 1], \n",
    "                  [1, 0, 2, 1, -2, 2]])\n",
    "\n",
    "\n",
    "beta = np.array([[1, 2, -2, 1], \n",
    "                 [1, -1, 1, 2], \n",
    "                 [3, 1, -1, 1]])\n",
    "\n",
    "\n",
    "x = np.array([1, 1, 0, 0, 1, 1])\n",
    "\n",
    "y = np.array([0, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.],\n",
      "        [7.],\n",
      "        [8.],\n",
      "        [2.]], dtype=torch.float64, grad_fn=<ThAddBackward>)\n",
      "tensor([[0.8808],\n",
      "        [0.9991],\n",
      "        [0.9997],\n",
      "        [0.8808]], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[2.7604],\n",
      "        [3.6430],\n",
      "        [4.5226]], dtype=torch.float64, grad_fn=<ThAddBackward>)\n",
      "tensor([[0.1082],\n",
      "        [0.2615],\n",
      "        [0.6303]], dtype=torch.float64, grad_fn=<DivBackward1>)\n",
      "tensor(1.3412, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "tensor([[ 0.8676,  1.8676, -3.0000,  0.0000,  0.8676, -3.1324],\n",
      "        [ 2.9986,  0.9986,  2.0000,  1.0000, -0.0014,  1.9986],\n",
      "        [ 2.0005,  2.0005,  2.0000,  2.0000,  2.0005,  1.0005],\n",
      "        [ 1.0775,  0.0775,  2.0000,  1.0000, -1.9225,  2.0775]],\n",
      "       dtype=torch.float64, grad_fn=<ThSubBackward>)\n",
      "tensor([[ 0.9047,  1.8919, -2.1082,  0.9047],\n",
      "        [ 1.6505, -0.2622,  1.7382,  2.6505],\n",
      "        [ 2.4449,  0.3703, -1.6301,  0.4449]],\n",
      "       dtype=torch.float64, grad_fn=<ThSubBackward>)\n",
      "tensor([[0.8676],\n",
      "        [0.9986],\n",
      "        [1.0005],\n",
      "        [1.0775]], dtype=torch.float64, grad_fn=<ThSubBackward>)\n",
      "tensor([[0.8918],\n",
      "        [1.7385],\n",
      "        [0.3697]], dtype=torch.float64, grad_fn=<ThSubBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "tensor_alpha = Variable(torch.DoubleTensor(alpha), requires_grad=True)\n",
    "tensor_beta = Variable(torch.DoubleTensor(beta), requires_grad=True)\n",
    "tensor_x = torch.DoubleTensor(x.reshape(x.shape[0], 1))\n",
    "tensor_y = torch.DoubleTensor(y.reshape(y.shape[0], 1))\n",
    "tensor_bias1 = Variable(torch.DoubleTensor(np.ones((4,1))), requires_grad=True)\n",
    "tensor_bias2 = Variable(torch.DoubleTensor(np.ones((3,1))), requires_grad=True)\n",
    "\n",
    "a = torch.mm(tensor_alpha, tensor_x)\n",
    "a = a + tensor_bias1\n",
    "print(a)\n",
    "z = F.sigmoid(a)\n",
    "print(z)\n",
    "b = torch.mm(tensor_beta ,z)\n",
    "b = b + tensor_bias2\n",
    "print(b)\n",
    "y_pred = torch.exp(b) / torch.sum( torch.exp(b) )\n",
    "print(y_pred)\n",
    "loss = -torch.sum(tensor_y * torch.log(y_pred))\n",
    "print(loss)\n",
    "loss.backward()\n",
    "tensor_alpha = tensor_alpha - tensor_alpha.grad\n",
    "print(tensor_alpha)\n",
    "tensor_beta = tensor_beta - tensor_beta.grad\n",
    "print(tensor_beta)\n",
    "tensor_bias1 = tensor_bias1 - tensor_bias1.grad\n",
    "print(tensor_bias1)\n",
    "tensor_bias2 = tensor_bias2 - tensor_bias2.grad\n",
    "print(tensor_bias2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.3382],\n",
      "        [6.9928],\n",
      "        [8.0027],\n",
      "        [2.3877]], dtype=torch.float64, grad_fn=<ThAddBackward>)\n",
      "tensor([[0.7922],\n",
      "        [0.9991],\n",
      "        [0.9997],\n",
      "        [0.9159]], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[2.2198],\n",
      "        [6.9492],\n",
      "        [1.4544]], dtype=torch.float64, grad_fn=<ThAddBackward>)\n",
      "tensor([[0.0087],\n",
      "        [0.9872],\n",
      "        [0.0041]], dtype=torch.float64, grad_fn=<DivBackward1>)\n",
      "tensor(0.0129, dtype=torch.float64, grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "a = torch.mm(tensor_alpha, tensor_x)\n",
    "a = a + tensor_bias1\n",
    "print(a)\n",
    "z = F.sigmoid(a)\n",
    "print(z)\n",
    "b = torch.mm(tensor_beta ,z)\n",
    "b = b + tensor_bias2\n",
    "print(b)\n",
    "y_pred = torch.exp(b) / torch.sum( torch.exp(b) )\n",
    "print(y_pred)\n",
    "loss = -torch.sum(tensor_y * torch.log(y_pred))\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
